# -*- coding: utf-8 -*-
"""Submission Project NLP dengan Tensorflow

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hs_NVVdXSgzOpTc6UsD0-ekw5OA2HRKk

<h2><b>Nama : Victory Herawidatama Esa Putra</b></h2>
<h3><b> Email : 18101105@ittelkom-pwt.ac.id </b></h3>

**Source Code yang digunakan untuk upload file csv**
"""

from google.colab import files
file = files.upload()

"""**Import libraries yang digunakan**"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.models import Model
from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding
from keras.preprocessing.text import Tokenizer
from keras.preprocessing import sequence
from keras.callbacks import EarlyStopping
# %matplotlib inline

"""**Load data untuk ditampilkan dengan font latin-1**
<p><b>Menampilkan 5 data teratas</b> </p>
"""

df = pd.read_csv('spam.csv', delimiter=',', encoding='latin-1' )
df.head()

"""**Menghapus element yang tidak dibutuhkan pada kolom csv**"""

df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)
df.info()

"""**Proses plotting menggunakan diagram batang antara ham dan spam messsage**"""

sns.countplot(df.v1)
plt.xlabel('Label')
plt.title('Number of ham and spam messsage')

"""**Membuat parameter untuk input dan output vector untuk proses label**"""

X = df.v2
Y = df.v1
le = LabelEncoder()
Y = le.fit_transform(Y)
Y = Y.reshape(-1,1)

"""**Split data untuk training dan test data**"""

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)

"""**Proses Tokenizer dengan mengubah teks menjadi urutan & menambahkan padding**"""

max_words = 1000
max_len = 150
token = Tokenizer(num_words=max_words)
token.fit_on_texts(X_train)
sequences = token.texts_to_sequences(X_train)
sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_len)

"""**Proses Modelling data menggunakan models Sequential dengan Embedding dan LSTM pada arsitektur model**"""

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Embedding(max_words, 50, input_length=max_len))
model.add(tf.keras.layers.LSTM(64))
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(1, activation='sigmoid')) 

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

"""**Menampilkan model yang telah terbentuk berdasarkan parameter yang sudah ditentukan sebelumnya**"""

model.summary()

"""**Pendefinisian fungsi callbacks yang membatasi test model ketika mencapai akurasi tertentu**"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.85):
      print("\nAkurasi telah mencapai >85%!")
      self.model.stop_training = True
callbacks = myCallback()

"""**Proses Training menggunakan model fit dengan epochs 20 menggunakan fungsi callbacks**"""

test = model.fit(sequences_matrix,Y_train,batch_size=128,epochs=20,
          validation_split=0.2)
#Callbacks tidak digunakan karena rata - rata setiap pengujian log mencapai akurasi diatas 75%

test_sequences = token.texts_to_sequences(X_test)
test_sequences_matrix = sequence.pad_sequences(test_sequences, maxlen=max_len)

accur = model.evaluate(test_sequences_matrix, Y_test)

accur = test.history['accuracy']
val_accur = test.history['val_accuracy']
loss = test.history['loss']
val_loss = test.history['val_loss']

epochs = range(len(accur))

plt.figure(figsize = (12, 8))
plt.plot(epochs, accur, 'r', label = 'Training accuracy')
plt.plot(epochs, val_accur, 'b', label = 'Validation accuracy')
plt.title('Training and Validation accuracy')
plt.legend(loc = 0)
plt.show()